{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/makaveli10/stylegan3/blob/main/face_merge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Face Morphing - StyleGAN3\n",
        " Network details\n",
        " "
      ],
      "metadata": {
        "id": "zc_u4adNO7Vi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yrkC2wSJp2G6"
      },
      "outputs": [],
      "source": [
        "NETWORK = 'https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/stylegan3-r-ffhq-1024x1024.pkl'\n",
        "STEPS = 150\n",
        "FPS = 30\n",
        "FREEZE_STEPS = 30"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Upload images"
      ],
      "metadata": {
        "id": "NM5cTpCLPElK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXNu7QDmp8FD"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "if len(uploaded) != 1:\n",
        "  print(\"Upload exactly 1 file for source.\")\n",
        "else:\n",
        "  for k, v in uploaded.items():\n",
        "    _, ext = os.path.splitext(k)\n",
        "    os.remove(k)\n",
        "    SOURCE_NAME = f\"source{ext}\"\n",
        "    open(SOURCE_NAME, 'wb').write(v)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8b2XQrtzp96t"
      },
      "outputs": [],
      "source": [
        "uploaded = files.upload()\n",
        "\n",
        "if len(uploaded) != 1:\n",
        "  print(\"Upload exactly 1 file for target.\")\n",
        "else:\n",
        "  for k, v in uploaded.items():\n",
        "    _, ext = os.path.splitext(k)\n",
        "    os.remove(k)\n",
        "    TARGET_NAME = f\"target{ext}\"\n",
        "    open(TARGET_NAME, 'wb').write(v)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## CodeFormer Upsampling \n",
        "Upsample images if needed i.e. stylegan needs high resolution images to generate better latent vectors"
      ],
      "metadata": {
        "id": "nEA0wlT9PNLm"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CJpJEL2G9ptI"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/sczhou/CodeFormer.git\n",
        "\n",
        "import sys\n",
        "sys.path.insert(0, \"/content/CodeFormer\")\n",
        "!pip install -r CodeFormer/requirements.txt\n",
        "%cd CodeFormer\n",
        "!python basicsr/setup.py develop\n",
        "%cd ..\n",
        "!python CodeFormer/scripts/download_pretrained_models.py facelib\n",
        "!python CodeFormer/scripts/download_pretrained_models.py CodeFormer"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Uncomment if codeformer upsampling needed."
      ],
      "metadata": {
        "id": "SIX-JGF8Pgtw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "nF2uPnII5-WT"
      },
      "outputs": [],
      "source": [
        "# CodeFormer restore image\n",
        "# cmd = f\"python CodeFormer/inference_codeformer.py -w 0.7 --input_path ./{SOURCE_NAME} -o ./\"\n",
        "# !{cmd}\n",
        "# cmd = f\"python CodeFormer/inference_codeformer.py -w 0.7 --input_path ./{TARGET_NAME} -o ./\"\n",
        "# !{cmd}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0P_Nq406qCyT"
      },
      "outputs": [],
      "source": [
        "!wget http://dlib.net/files/shape_predictor_5_face_landmarks.dat.bz2\n",
        "!bzip2 -d shape_predictor_5_face_landmarks.dat.bz2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_5EE0c_8qCwA"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "!git clone https://github.com/makaveli10/stylegan3\n",
        "!pip install ninja\n",
        "sys.path.insert(0, \"/content/stylegan3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Detect face and crop"
      ],
      "metadata": {
        "id": "6NycrNdjPu9B"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1bzoj2BIqCtt"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import dlib\n",
        "\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor('shape_predictor_5_face_landmarks.dat')\n",
        "\n",
        "def find_eyes(img):\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "  rects = detector(gray, 0)\n",
        "  \n",
        "  if len(rects) == 0:\n",
        "    raise ValueError(\"No faces detected\")\n",
        "  elif len(rects) > 1:\n",
        "    raise ValueError(\"Multiple faces detected\")\n",
        "\n",
        "  shape = predictor(gray, rects[0])\n",
        "  features = []\n",
        "\n",
        "  for i in range(0, 5):\n",
        "    features.append((i, (shape.part(i).x, shape.part(i).y)))\n",
        "\n",
        "  return (int(features[3][1][0] + features[2][1][0]) // 2, \\\n",
        "    int(features[3][1][1] + features[2][1][1]) // 2), \\\n",
        "    (int(features[1][1][0] + features[0][1][0]) // 2, \\\n",
        "    int(features[1][1][1] + features[0][1][1]) // 2)\n",
        "\n",
        "def crop_stylegan(img):\n",
        "  left_eye, right_eye = find_eyes(img)\n",
        "  d = abs(right_eye[0] - left_eye[0])\n",
        "  z = 255/d\n",
        "  ar = img.shape[0]/img.shape[1]\n",
        "  w = img.shape[1] * z\n",
        "  img2 = cv2.resize(img, (int(w), int(w*ar)))\n",
        "  bordersize = 1024\n",
        "  img3 = cv2.copyMakeBorder(\n",
        "      img2,\n",
        "      top=bordersize,\n",
        "      bottom=bordersize,\n",
        "      left=bordersize,\n",
        "      right=bordersize,\n",
        "      borderType=cv2.BORDER_REPLICATE)\n",
        "\n",
        "  left_eye2, right_eye2 = find_eyes(img3)\n",
        "\n",
        "  crop1 = left_eye2[0] - 385 \n",
        "  crop0 = left_eye2[1] - 490\n",
        "  return img3[crop0:crop0+1024,crop1:crop1+1024]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "9r3MRj4yqCrR"
      },
      "outputs": [],
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import cv2\n",
        "print(SOURCE_NAME)\n",
        "# image_source = cv2.imread(SOURCE_NAME)\n",
        "image_source = cv2.imread(f\"./final_results/{SOURCE_NAME.split('.')[0]}.png\")\n",
        "if image_source is None:\n",
        "    raise ValueError(\"Source image not found\")\n",
        "\n",
        "image_target = cv2.imread(TARGET_NAME)\n",
        "# image_target = cv2.imread(f\"./final_results/{TARGET_NAME}\")\n",
        "if image_target is None:\n",
        "    raise ValueError(\"Source image not found\")\n",
        "\n",
        "cropped_source = crop_stylegan(image_source)\n",
        "cropped_target = crop_stylegan(image_target)\n",
        "\n",
        "img = cv2.cvtColor(cropped_source, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img)\n",
        "plt.title('source')\n",
        "plt.show()\n",
        "\n",
        "img = cv2.cvtColor(cropped_target, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img)\n",
        "plt.title('target')\n",
        "plt.show()\n",
        "\n",
        "cv2.imwrite(\"cropped_source.png\", cropped_source)\n",
        "cv2.imwrite(\"cropped_target.png\", cropped_target)\n",
        "\n",
        "#print(find_eyes(cropped_source))\n",
        "#print(find_eyes(cropped_target))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Generate StyleGAN3 Latents"
      ],
      "metadata": {
        "id": "NBYUJmPYQNCS"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rtpbe0zfqCpN"
      },
      "outputs": [],
      "source": [
        "cmd = f\"python /content/stylegan3/projector.py --save-video 0 --num-steps 1000 --outdir=vineet --target=cropped_source.png --network={NETWORK}\"\n",
        "!{cmd}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DF-OZVEUqCnN"
      },
      "outputs": [],
      "source": [
        "cmd = f\"python /content/stylegan3/projector.py --save-video 0 --num-steps 1000 --outdir=medel --target=cropped_target.png --network={NETWORK}\"\n",
        "!{cmd}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zYNZrNHc-iNE"
      },
      "outputs": [],
      "source": [
        "img_gan_source = cv2.imread('/content/vineet/proj.png')\n",
        "img = cv2.cvtColor(img_gan_source, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img)\n",
        "plt.title('source-gan')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q3l2f29GqCi9"
      },
      "outputs": [],
      "source": [
        "img_gan_target = cv2.imread('/content/out_target/proj.png')\n",
        "img = cv2.cvtColor(img_gan_target, cv2.COLOR_BGR2RGB)\n",
        "plt.imshow(img)\n",
        "plt.title('target-gan')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjBjuSgu3rvb"
      },
      "outputs": [],
      "source": [
        "!pip install imageio-ffmpeg"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merge Faces"
      ],
      "metadata": {
        "id": "5Gm0-PXgQSyA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YaIkEET1qCg1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import dnnlib\n",
        "import legacy\n",
        "import PIL.Image\n",
        "import numpy as np\n",
        "import imageio\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "SOURCE='vineet'\n",
        "TARGET='medel'\n",
        "\n",
        "lvec1 = np.load(f'/content/{SOURCE}/projected_w.npz')['w']\n",
        "lvec2 = np.load(f'/content/{TARGET}/projected_w.npz')['w']\n",
        "\n",
        "# network_pkl = \"https://nvlabs-fi-cdn.nvidia.com/stylegan2-ada-pytorch/pretrained/ffhq.pkl\"\n",
        "device = torch.device('cuda')\n",
        "with dnnlib.util.open_url(NETWORK) as fp:\n",
        "    G = legacy.load_network_pkl(fp)['G_ema'].requires_grad_(False).to(device) # type: ignore\n",
        "\n",
        "diff = lvec2 - lvec1\n",
        "step = diff / STEPS\n",
        "current = lvec1.copy()\n",
        "target_uint8 = np.array([1024,1024,3], dtype=np.uint8)\n",
        "\n",
        "video = imageio.get_writer('/content/movie.mp4', mode='I', fps=FPS, codec='libx264', bitrate='16M')\n",
        "\n",
        "for j in tqdm(range(STEPS)):\n",
        "  z = torch.from_numpy(current).to(device)\n",
        "  synth_image = G.synthesis(z, noise_mode='const')\n",
        "  synth_image = (synth_image + 1) * (255/2)\n",
        "  synth_image = synth_image.permute(0, 2, 3, 1).clamp(0, 255).to(torch.uint8)[0].cpu().numpy()\n",
        "\n",
        "  repeat = FREEZE_STEPS if j==0 or j==(STEPS-1) else 1\n",
        "   \n",
        "  for i in range(repeat):\n",
        "    video.append_data(synth_image)\n",
        "  if j == STEPS/2:\n",
        "    cv2.imwrite('./merge.png', cv2.cvtColor(synth_image, cv2.COLOR_RGB2BGR))\n",
        "  current = current + step\n",
        "\n",
        "\n",
        "video.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gv7rgj1MqCeq"
      },
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "files.download(\"movie.mp4\") "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOL8l9OL8lwuMyXikHZTcvV",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}